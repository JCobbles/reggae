{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import math as tfm\n",
    "\n",
    "from reggae.data_loaders import load_barenco_puma, DataHolder\n",
    "from gpflow.conditionals.util import sample_mvn\n",
    "from gpflow.conditionals import base_conditional\n",
    "from gpflow.kernels import SquaredExponential\n",
    "from gpflow import Parameter\n",
    "from gpflow.utilities import positive\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "f64 = np.float64\n",
    "#was tf 2.3.1 and tfp 0.11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 7)\n",
      "(100, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "           cARP1-0hrs.CEL  cARP1-2hrs.CEL  cARP1-4hrs.CEL  cARP1-6hrs.CEL  \\\nDDB2             7.593549        9.122439       10.192915       10.154778   \nBIK              2.905667        6.756250        8.154665        8.222898   \nTNFRSF10b        3.949437        7.283147        8.395333        8.147465   \np21              1.268160        7.375613        9.600847        8.485615   \nSESN1            6.354029        7.703226        8.818485        8.608104   \n\n           cARP1-8hrs.CEL  cARP1-10hrs.CEL  cARP1-12hrs.CEL  cARP2-0hrs.CEL  \\\nDDB2            10.103455         9.529804         9.567770        7.464445   \nBIK              8.074595         7.026262         7.001658        4.649182   \nTNFRSF10b        8.456766         7.370946         7.409659        3.828976   \np21              8.134573         7.045323         7.171770       -0.094250   \nSESN1            8.803210         7.860224         7.981910        6.613610   \n\n           cARP2-2hrs.CEL  cARP2-4hrs.CEL  ...  cARP2-8hrs.CEL  \\\nDDB2             8.611248        9.255834  ...        8.149388   \nBIK              5.926949        7.346142  ...        4.659069   \nTNFRSF10b        6.362601        7.576429  ...        5.897853   \np21              6.530376        7.910253  ...        4.803834   \nSESN1            7.371426        7.885798  ...        6.658747   \n\n           cARP2-10hrs.CEL  cARP2-12hrs.CEL  cARP3-0hrs.CEL  cARP3-2hrs.CEL  \\\nDDB2              9.367364         9.342251        7.353484        7.665469   \nBIK               6.772798         7.005289        5.204797        4.139740   \nTNFRSF10b         6.975229         7.280981        4.822874        5.389953   \np21               6.971544         6.890152        1.397808        6.120564   \nSESN1             7.583440         7.503870        6.158661        6.178353   \n\n           cARP3-4hrs.CEL  cARP3-6hrs.CEL  cARP3-8hrs.CEL  cARP3-10hrs.CEL  \\\nDDB2             9.798868        9.345199        8.757635         8.357981   \nBIK              8.056000        7.122196        5.633847         4.488936   \nTNFRSF10b        7.749164        7.387181        6.083331         6.024036   \np21              8.724741        7.821537        6.483512         5.945312   \nSESN1            8.384142        7.993519        7.102504         6.990250   \n\n           cARP3-12hrs.CEL  \nDDB2              9.026733  \nBIK               5.724764  \nTNFRSF10b         6.771154  \np21               6.653475  \nSESN1             7.327648  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cARP1-0hrs.CEL</th>\n      <th>cARP1-2hrs.CEL</th>\n      <th>cARP1-4hrs.CEL</th>\n      <th>cARP1-6hrs.CEL</th>\n      <th>cARP1-8hrs.CEL</th>\n      <th>cARP1-10hrs.CEL</th>\n      <th>cARP1-12hrs.CEL</th>\n      <th>cARP2-0hrs.CEL</th>\n      <th>cARP2-2hrs.CEL</th>\n      <th>cARP2-4hrs.CEL</th>\n      <th>...</th>\n      <th>cARP2-8hrs.CEL</th>\n      <th>cARP2-10hrs.CEL</th>\n      <th>cARP2-12hrs.CEL</th>\n      <th>cARP3-0hrs.CEL</th>\n      <th>cARP3-2hrs.CEL</th>\n      <th>cARP3-4hrs.CEL</th>\n      <th>cARP3-6hrs.CEL</th>\n      <th>cARP3-8hrs.CEL</th>\n      <th>cARP3-10hrs.CEL</th>\n      <th>cARP3-12hrs.CEL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>DDB2</th>\n      <td>7.593549</td>\n      <td>9.122439</td>\n      <td>10.192915</td>\n      <td>10.154778</td>\n      <td>10.103455</td>\n      <td>9.529804</td>\n      <td>9.567770</td>\n      <td>7.464445</td>\n      <td>8.611248</td>\n      <td>9.255834</td>\n      <td>...</td>\n      <td>8.149388</td>\n      <td>9.367364</td>\n      <td>9.342251</td>\n      <td>7.353484</td>\n      <td>7.665469</td>\n      <td>9.798868</td>\n      <td>9.345199</td>\n      <td>8.757635</td>\n      <td>8.357981</td>\n      <td>9.026733</td>\n    </tr>\n    <tr>\n      <th>BIK</th>\n      <td>2.905667</td>\n      <td>6.756250</td>\n      <td>8.154665</td>\n      <td>8.222898</td>\n      <td>8.074595</td>\n      <td>7.026262</td>\n      <td>7.001658</td>\n      <td>4.649182</td>\n      <td>5.926949</td>\n      <td>7.346142</td>\n      <td>...</td>\n      <td>4.659069</td>\n      <td>6.772798</td>\n      <td>7.005289</td>\n      <td>5.204797</td>\n      <td>4.139740</td>\n      <td>8.056000</td>\n      <td>7.122196</td>\n      <td>5.633847</td>\n      <td>4.488936</td>\n      <td>5.724764</td>\n    </tr>\n    <tr>\n      <th>TNFRSF10b</th>\n      <td>3.949437</td>\n      <td>7.283147</td>\n      <td>8.395333</td>\n      <td>8.147465</td>\n      <td>8.456766</td>\n      <td>7.370946</td>\n      <td>7.409659</td>\n      <td>3.828976</td>\n      <td>6.362601</td>\n      <td>7.576429</td>\n      <td>...</td>\n      <td>5.897853</td>\n      <td>6.975229</td>\n      <td>7.280981</td>\n      <td>4.822874</td>\n      <td>5.389953</td>\n      <td>7.749164</td>\n      <td>7.387181</td>\n      <td>6.083331</td>\n      <td>6.024036</td>\n      <td>6.771154</td>\n    </tr>\n    <tr>\n      <th>p21</th>\n      <td>1.268160</td>\n      <td>7.375613</td>\n      <td>9.600847</td>\n      <td>8.485615</td>\n      <td>8.134573</td>\n      <td>7.045323</td>\n      <td>7.171770</td>\n      <td>-0.094250</td>\n      <td>6.530376</td>\n      <td>7.910253</td>\n      <td>...</td>\n      <td>4.803834</td>\n      <td>6.971544</td>\n      <td>6.890152</td>\n      <td>1.397808</td>\n      <td>6.120564</td>\n      <td>8.724741</td>\n      <td>7.821537</td>\n      <td>6.483512</td>\n      <td>5.945312</td>\n      <td>6.653475</td>\n    </tr>\n    <tr>\n      <th>SESN1</th>\n      <td>6.354029</td>\n      <td>7.703226</td>\n      <td>8.818485</td>\n      <td>8.608104</td>\n      <td>8.803210</td>\n      <td>7.860224</td>\n      <td>7.981910</td>\n      <td>6.613610</td>\n      <td>7.371426</td>\n      <td>7.885798</td>\n      <td>...</td>\n      <td>6.658747</td>\n      <td>7.583440</td>\n      <td>7.503870</td>\n      <td>6.158661</td>\n      <td>6.178353</td>\n      <td>8.384142</td>\n      <td>7.993519</td>\n      <td>7.102504</td>\n      <td>6.990250</td>\n      <td>7.327648</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_observed, f_observed, σ2_m_pre, σ2_f_pre, t = load_barenco_puma('../data/')\n",
    "\n",
    "m_df, m_observed = m_observed\n",
    "f_df, f_observed = f_observed\n",
    "# Shape of m_observed = (replicates, genes, times)\n",
    "m_observed = m_observed\n",
    "f_observed = f_observed\n",
    "data = (m_observed, f_observed)\n",
    "\n",
    "σ2_m_pre = f64(σ2_m_pre)\n",
    "σ2_f_pre = f64(σ2_f_pre)\n",
    "noise_data = (σ2_m_pre, σ2_f_pre)\n",
    "\n",
    "print(m_observed.shape)\n",
    "display(m_df)\n",
    "num_genes = m_observed.shape[1]\n",
    "num_tfs = f_observed.shape[1]\n",
    "N_m = m_observed.shape[2]\n",
    "granularity = 100\n",
    "t_start = f64(0)\n",
    "t_end = f64(1)\n",
    "t = tf.reshape(tf.linspace(t_start, t_end, granularity), (-1, 1))\n",
    "t_inducing = tf.reshape(tf.linspace(t_start, t_end, 7), (-1, 1))\n",
    "print(t.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class ODEModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_genes, num_tfs, t, t_inducing):\n",
    "        super(ODEModel, self).__init__()\n",
    "        self.num_genes = num_genes\n",
    "        self.num_tfs = num_tfs\n",
    "        self.num_inducing = 7\n",
    "        self.kernel = SquaredExponential(lengthscales=f64(0.1))\n",
    "        self.t = t\n",
    "        self.t_inducing = t_inducing\n",
    "        # t_1, t_2 = get_time_square(t, 100)\n",
    "        # self.t_dist = t_1-t_2\n",
    "        self.decay_rate = tf.Variable(tf.ones((self.num_genes,1), dtype='float64'))\n",
    "        self.basal_rate = tf.Variable(tf.ones((self.num_genes,1), dtype='float64'))\n",
    "        self.w = tf.Variable(tf.ones((self.num_genes, self.num_tfs), dtype='float64'))\n",
    "        # self.l2 = tf.Variable(tf.ones(self.num_tfs, dtype='float64'))\n",
    "        # self.v = tf.Variable(tf.ones(self.num_tfs, dtype='float64'))\n",
    "        self.inducing_points = tf.Variable(tf.random.normal((self.num_inducing,1), dtype='float64'))\n",
    "        self.likelihood_variance = Parameter(f64(1), transform=positive(lower=1e-6))\n",
    "\n",
    "    def call(self, t, h):\n",
    "        print(t)\n",
    "        # h is of shape (num_genes, 1)\n",
    "        decay = tf.multiply(self.decay_rate, h)\n",
    "        # print('decay shape, h shape', decay.shape, h.shape, t)\n",
    "        p = self.get_tfs(tf.reshape(t, (-1, 1)))\n",
    "        # Gp = tf.reshape(t, (-1, 1))\n",
    "\n",
    "        Gp = self.G(p)\n",
    "        # print(self.basal_rate + Gp - decay)\n",
    "        return self.basal_rate + Gp - decay\n",
    "        # return tf.multiply(h, t)\n",
    "\n",
    "    def K(self):\n",
    "        sq_dist = tf.divide(\n",
    "            tfm.square(self.t_dist), tf.reshape(2*self.l2, (-1, 1, 1)))\n",
    "        return tf.reshape(self.v, (-1, 1, 1)) * tfm.exp(-sq_dist)\n",
    "\n",
    "    def get_tfs(self, at):\n",
    "        y = self.inducing_points\n",
    "\n",
    "        kmm = self.kernel(self.t_inducing) #X_data\n",
    "        knn = self.kernel(at, full_cov=False) #X_new\n",
    "        kmn = self.kernel(self.t_inducing, at)\n",
    "        # print(kmm.shape, knn.shape, kmn.shape)\n",
    "        num_data = self.num_inducing\n",
    "        s = tf.linalg.diag(tf.fill([num_data], self.likelihood_variance))\n",
    "\n",
    "        f_mean_zero, f_var = base_conditional(\n",
    "            kmn, kmm + s, knn, y, full_cov=False, white=False\n",
    "        )  # [N, P], [N, P] or [P, N, N]\n",
    "        f_mean = f_mean_zero\n",
    "        return f_mean #exand dims 0\n",
    "\n",
    "    def euler_maruyama(self):\n",
    "        pass\n",
    "\n",
    "    def G(self, p):\n",
    "        interactions =  tf.matmul(self.w, tfm.log(p+1e-100)) #+ w_0 (TODO)\n",
    "        return tfm.sigmoid(interactions) # TF Activation Function (sigmoid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "model = ODEModel(num_genes, num_tfs, t, t_inducing)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start end 0.0 1.0\n",
      "Epoch 0\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(1e-12, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe207fc3a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.002112161950513746, shape=(), dtype=float64)\n",
      "tf.Tensor(0.002112161950513746, shape=(), dtype=float64)\n",
      "tf.Tensor(0.002112161950513746, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe207ff18c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.004224323901027492, shape=(), dtype=float64)\n",
      "tf.Tensor(0.004224323901027492, shape=(), dtype=float64)\n",
      "tf.Tensor(0.004224323901027492, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe207ff18c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.006336485851541238, shape=(), dtype=float64)\n",
      "tf.Tensor(0.006336485851541238, shape=(), dtype=float64)\n",
      "tf.Tensor(0.006336485851541238, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe20820f170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.014006156041000136, shape=(), dtype=float64)\n",
      "tf.Tensor(0.014006156041000136, shape=(), dtype=float64)\n",
      "tf.Tensor(0.014006156041000136, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe20820fb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.021675826230459033, shape=(), dtype=float64)\n",
      "tf.Tensor(0.021675826230459033, shape=(), dtype=float64)\n",
      "tf.Tensor(0.021675826230459033, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe2082d3a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.02934549641991793, shape=(), dtype=float64)\n",
      "tf.Tensor(0.02934549641991793, shape=(), dtype=float64)\n",
      "tf.Tensor(0.02934549641991793, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe20865f710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.03701516660937683, shape=(), dtype=float64)\n",
      "tf.Tensor(0.03701516660937683, shape=(), dtype=float64)\n",
      "tf.Tensor(0.03701516660937683, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe20865f710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.08205830464950907, shape=(), dtype=float64)\n",
      "tf.Tensor(0.08205830464950907, shape=(), dtype=float64)\n",
      "tf.Tensor(0.08205830464950907, shape=(), dtype=float64)\n",
      "tf.Tensor(0.08205830464950907, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05953673562944295, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05953673562944295, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05953673562944295, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05953673562944295, shape=(), dtype=float64)\n",
      "tf.Tensor(0.04827595111940989, shape=(), dtype=float64)\n",
      "tf.Tensor(0.04827595111940989, shape=(), dtype=float64)\n",
      "tf.Tensor(0.04827595111940989, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe20865f710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.05953673562944295, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05953673562944295, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05953673562944295, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05953673562944295, shape=(), dtype=float64)\n",
      "tf.Tensor(0.053906343374426416, shape=(), dtype=float64)\n",
      "tf.Tensor(0.053906343374426416, shape=(), dtype=float64)\n",
      "tf.Tensor(0.053906343374426416, shape=(), dtype=float64)\n",
      "tf.Tensor(0.053906343374426416, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051091147246918156, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051091147246918156, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051091147246918156, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe205c008c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.05390634337442642, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05390634337442642, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05390634337442642, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05390634337442642, shape=(), dtype=float64)\n",
      "tf.Tensor(0.052498745310672286, shape=(), dtype=float64)\n",
      "tf.Tensor(0.052498745310672286, shape=(), dtype=float64)\n",
      "tf.Tensor(0.052498745310672286, shape=(), dtype=float64)\n",
      "tf.Tensor(0.052498745310672286, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051794946278795224, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051794946278795224, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051794946278795224, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051794946278795224, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05144304676285669, shape=(), dtype=float64)\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe20ff17a50>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Users/jacob/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/math/ode/dormand_prince.py\", line 695, in _write_solution_components\n",
      "    return updated_arrays  File \"/Users/jacob/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/util/nest.py\", line 660, in map_structure\n",
      "    expand_composites=expand_composites)  File \"/Users/jacob/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/util/nest.py\", line 659, in <listcomp>\n",
      "    structure[0], [func(*x) for x in entries],  File \"/Users/jacob/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/math/ode/dormand_prince.py\", line 692, in <lambda>\n",
      "    write_solution = lambda array, tensor: array.write(time_id, tensor)  File \"/Users/jacob/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n",
      "    error_in_function=error_in_function)\n",
      "==================================\n",
      "tf.Tensor(0.05144304676285669, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05144304676285669, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05144304676285669, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05126709700488742, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05126709700488742, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05126709700488742, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05126709700488742, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05117912212590279, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05117912212590279, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05117912212590279, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe206ba23b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.05126709700488742, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05126709700488742, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05126709700488742, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05126709700488742, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05122310956539511, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05122310956539511, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05122310956539511, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05122310956539511, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051201115845648945, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051201115845648945, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051201115845648945, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe2075995f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.0512231095653951, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0512231095653951, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0512231095653951, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0512231095653951, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05121211270552203, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05121211270552203, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05121211270552203, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05121211270552203, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120661427558548, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120661427558548, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120661427558548, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe206b09440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.05121211270552202, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05121211270552202, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05121211270552202, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05121211270552202, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120936349055375, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120936349055375, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120936349055375, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120936349055375, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120798888306962, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120798888306962, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120798888306962, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe20683e560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.05120936349055376, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120936349055376, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120936349055376, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120936349055376, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208676186811686, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208676186811686, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208676186811686, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208676186811686, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208332534940657, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208332534940657, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208332534940657, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208332534940657, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208160709005135, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208160709005135, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208160709005135, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208160709005135, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120807479603738, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120807479603738, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120807479603738, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120807479603738, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0512080318395535, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0512080318395535, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0512080318395535, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe206768ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.051208074796037374, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208074796037374, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208074796037374, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208074796037374, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120805331779544, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120805331779544, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120805331779544, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120805331779544, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208042578674465, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208042578674465, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208042578674465, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208042578674465, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120803720911398, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120803720911398, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120803720911398, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe1ff9ec290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.051208042578674465, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208042578674465, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208042578674465, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208042578674465, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208039893894226, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208039893894226, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208039893894226, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe1ff9ec290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.05120804257867447, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804257867447, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804257867447, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804257867447, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804123628435, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804123628435, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804123628435, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804123628435, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208040565089284, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208040565089284, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208040565089284, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe2002c6b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.05120804123628434, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804123628434, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804123628434, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804123628434, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804090068681, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804090068681, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804090068681, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804090068681, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804073288805, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804073288805, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804073288805, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe2002c6b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.05120804090068682, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804090068682, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804090068682, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804090068682, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804081678743, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804081678743, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804081678743, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804081678743, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208040774837746, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208040774837746, shape=(), dtype=float64)\n",
      "tf.Tensor(0.051208040774837746, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe2008bd4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.05120804081678744, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804081678744, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804081678744, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804081678744, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804079581259, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804079581259, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804079581259, shape=(), dtype=float64)\n",
      "tf.Tensor(0.05120804079581259, shape=(), dtype=float64)\n",
      "loss tf.Tensor(0.799251139163971, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(-1e-12, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(-1e-12, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(-1e-12, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(-1e-12, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(-1e-12, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(-1e-12, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.16666666666666666, shape=(), dtype=float64)\n",
      "tf.Tensor(0.16666666666566665, shape=(), dtype=float64)\n",
      "tf.Tensor(0.16666666666666666, shape=(), dtype=float64)\n",
      "tf.Tensor(0.16666666666666666, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7fe208073710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(nan, shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _EagerDefinedFunctionDeleter.__del__ at 0x7fe2e49157a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jacob/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 396, in __del__\n",
      "    context.remove_function(self.name)\n",
      "  File \"/Users/jacob/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 2364, in remove_function\n",
      "    context().remove_function(name)\n",
      "  File \"/Users/jacob/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 1192, in remove_function\n",
      "    pywrap_tfe.TFE_ContextRemoveFunction(self._handle, name)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function _EagerDefinedFunctionDeleter.__del__ at 0x7fe2e49157a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jacob/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 396, in __del__\n",
      "    context.remove_function(self.name)\n",
      "  File \"/Users/jacob/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 2364, in remove_function\n",
      "    context().remove_function(name)\n",
      "  File \"/Users/jacob/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 1192, in remove_function\n",
      "    pywrap_tfe.TFE_ContextRemoveFunction(self._handle, name)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <bound method WeakStructRef._cleanup of WeakStructRef(HashableWeakRef(<weakref at 0x7fe28b09e770; dead>))>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jacob/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 152, in _cleanup\n",
      "    def _cleanup(self, _):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input matrix is not invertible. [Op:MatrixTriangularSolve]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-31-a1e52205fd81>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mbasalrates\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecayrates\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlengthscales\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 43\u001B[0;31m \u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparams\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     44\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-31-a1e52205fd81>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     28\u001B[0m         \u001B[0;31m# print('basal', gradients)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m         \u001B[0mtrainable_variables\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkernel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m         \u001B[0mgradients\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainable_variables\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     31\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'gradients'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradients\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001B[0m in \u001B[0;36mgradient\u001B[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[1;32m   1084\u001B[0m         \u001B[0moutput_gradients\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_gradients\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1085\u001B[0m         \u001B[0msources_raw\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mflat_sources_raw\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1086\u001B[0;31m         unconnected_gradients=unconnected_gradients)\n\u001B[0m\u001B[1;32m   1087\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1088\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_persistent\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001B[0m in \u001B[0;36mimperative_grad\u001B[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[1;32m     75\u001B[0m       \u001B[0moutput_gradients\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m       \u001B[0msources_raw\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 77\u001B[0;31m       compat.as_str(unconnected_gradients.value))\n\u001B[0m",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/custom_gradient.py\u001B[0m in \u001B[0;36mactual_grad_fn\u001B[0;34m(*result_grads)\u001B[0m\n\u001B[1;32m    466\u001B[0m     \u001B[0;34m\"\"\"Custom grad fn wrapper.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    467\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mvariables\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 468\u001B[0;31m       \u001B[0minput_grads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvariable_grads\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mresult_grads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvariables\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvariables\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    469\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvariable_grads\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvariables\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    470\u001B[0m         raise ValueError(\"Must return gradient for each variable from \"\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/math/ode/base.py\u001B[0m in \u001B[0;36mgrad_fn\u001B[0;34m(*dresults, **kwargs)\u001B[0m\n\u001B[1;32m    461\u001B[0m               \u001B[0mreverse_to_result_time\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    462\u001B[0m               \u001B[0;34m(\u001B[0m\u001B[0minitial_n\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mterminal_augmented_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msolver_internal_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 463\u001B[0;31m               \u001B[0mback_prop\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    464\u001B[0m           )\n\u001B[1;32m    465\u001B[0m           (_, adjoint_state, adjoint_variables,\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001B[0m in \u001B[0;36mnew_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    603\u001B[0m                   \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__module__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'in a future version'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    604\u001B[0m                   if date is None else ('after %s' % date), instructions)\n\u001B[0;32m--> 605\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    606\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    607\u001B[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop_v2\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001B[0m\n\u001B[1;32m   2497\u001B[0m       \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2498\u001B[0m       \u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2499\u001B[0;31m       return_same_structure=True)\n\u001B[0m\u001B[1;32m   2500\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2501\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001B[0m\n\u001B[1;32m   2733\u001B[0m                                               list(loop_vars))\n\u001B[1;32m   2734\u001B[0m       \u001B[0;32mwhile\u001B[0m \u001B[0mcond\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2735\u001B[0;31m         \u001B[0mloop_vars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2736\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtry_to_pack\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_basetuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2737\u001B[0m           \u001B[0mpacked\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/math/ode/base.py\u001B[0m in \u001B[0;36mreverse_to_result_time\u001B[0;34m(n, augmented_state, solver_internal_state, _)\u001B[0m\n\u001B[1;32m    439\u001B[0m                 \u001B[0msolution_times\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mupper_bound_of_integration\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    440\u001B[0m                 \u001B[0mbatch_ndims\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_ndims\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 441\u001B[0;31m                 \u001B[0mprevious_solver_internal_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msolver_internal_state\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    442\u001B[0m             )\n\u001B[1;32m    443\u001B[0m             \u001B[0;31m# Results added an extra time dim of size 1, squeeze it.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/math/ode/base.py\u001B[0m in \u001B[0;36msolve\u001B[0;34m(self, ode_fn, initial_time, initial_state, solution_times, jacobian_fn, jacobian_sparsity, batch_ndims, previous_solver_internal_state, constants)\u001B[0m\n\u001B[1;32m    473\u001B[0m     \u001B[0;31m# custom_gradient will complain even if there are no variables in `ode_fn`.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    474\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtf1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvariable_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_variable_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muse_resource\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 475\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mgradient_helper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mflat_initial_state\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mflat_constants\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    476\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    477\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mabc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mabstractmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/custom_gradient.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *a, **k)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    260\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 261\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_f\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    262\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/custom_gradient.py\u001B[0m in \u001B[0;36mdecorated\u001B[0;34m(wrapped, args, kwargs)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    214\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 215\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0m_eager_mode_decorator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwrapped\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    216\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    217\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_graph_mode_decorator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwrapped\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/custom_gradient.py\u001B[0m in \u001B[0;36m_eager_mode_decorator\u001B[0;34m(f, args, kwargs)\u001B[0m\n\u001B[1;32m    436\u001B[0m   \u001B[0;34m\"\"\"Implement custom gradient decorator for eager mode.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    437\u001B[0m   \u001B[0;32mwith\u001B[0m \u001B[0mtape_lib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mVariableWatcher\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mvariable_watcher\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 438\u001B[0;31m     \u001B[0mresult\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    439\u001B[0m   \u001B[0margs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    440\u001B[0m   \u001B[0mall_inputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/math/ode/base.py\u001B[0m in \u001B[0;36mgradient_helper\u001B[0;34m(*flat_initial_state_and_constants)\u001B[0m\n\u001B[1;32m    237\u001B[0m           \u001B[0mjacobian_sparsity\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjacobian_sparsity\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    238\u001B[0m           \u001B[0mbatch_ndims\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_ndims\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 239\u001B[0;31m           \u001B[0mprevious_solver_internal_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mprevious_solver_internal_state\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    240\u001B[0m       )\n\u001B[1;32m    241\u001B[0m       results = Results(\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/math/ode/bdf.py\u001B[0m in \u001B[0;36m_solve\u001B[0;34m(self, ode_fn, initial_time, initial_state, solution_times, jacobian_fn, jacobian_sparsity, batch_ndims, previous_solver_internal_state)\u001B[0m\n\u001B[1;32m    634\u001B[0m                             advance_to_solution_time, [\n\u001B[1;32m    635\u001B[0m                                 \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdiagnostics\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterand\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msolver_internal_state\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 636\u001B[0;31m                                 \u001B[0mstate_vec_array\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime_array\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    637\u001B[0m                             ])\n\u001B[1;32m    638\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001B[0m in \u001B[0;36mnew_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    603\u001B[0m                   \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__module__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'in a future version'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    604\u001B[0m                   if date is None else ('after %s' % date), instructions)\n\u001B[0;32m--> 605\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    606\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    607\u001B[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop_v2\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001B[0m\n\u001B[1;32m   2497\u001B[0m       \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2498\u001B[0m       \u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2499\u001B[0;31m       return_same_structure=True)\n\u001B[0m\u001B[1;32m   2500\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2501\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001B[0m\n\u001B[1;32m   2733\u001B[0m                                               list(loop_vars))\n\u001B[1;32m   2734\u001B[0m       \u001B[0;32mwhile\u001B[0m \u001B[0mcond\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2735\u001B[0;31m         \u001B[0mloop_vars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2736\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtry_to_pack\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_basetuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2737\u001B[0m           \u001B[0mpacked\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/math/ode/bdf.py\u001B[0m in \u001B[0;36madvance_to_solution_time\u001B[0;34m(n, diagnostics, iterand, solver_internal_state, state_vec_array, time_array)\u001B[0m\n\u001B[1;32m    264\u001B[0m       ] = tf.while_loop(step_cond, step, [\n\u001B[1;32m    265\u001B[0m           \u001B[0mnth_solution_time\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdiagnostics\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterand\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msolver_internal_state\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 266\u001B[0;31m           \u001B[0mstate_vec_array\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime_array\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    267\u001B[0m       ])\n\u001B[1;32m    268\u001B[0m       state_vec_array = state_vec_array.write(\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001B[0m in \u001B[0;36mnew_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    603\u001B[0m                   \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__module__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'in a future version'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    604\u001B[0m                   if date is None else ('after %s' % date), instructions)\n\u001B[0;32m--> 605\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    606\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    607\u001B[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop_v2\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001B[0m\n\u001B[1;32m   2497\u001B[0m       \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2498\u001B[0m       \u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2499\u001B[0;31m       return_same_structure=True)\n\u001B[0m\u001B[1;32m   2500\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2501\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001B[0m\n\u001B[1;32m   2733\u001B[0m                                               list(loop_vars))\n\u001B[1;32m   2734\u001B[0m       \u001B[0;32mwhile\u001B[0m \u001B[0mcond\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2735\u001B[0;31m         \u001B[0mloop_vars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2736\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtry_to_pack\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_basetuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2737\u001B[0m           \u001B[0mpacked\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/math/ode/bdf.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(next_time, diagnostics, iterand, solver_internal_state, state_vec_array, time_array)\u001B[0m\n\u001B[1;32m    295\u001B[0m       _, diagnostics, iterand, solver_internal_state = tf.while_loop(\n\u001B[1;32m    296\u001B[0m           \u001B[0mmaybe_step_cond\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmaybe_step\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 297\u001B[0;31m           [False, diagnostics, iterand, solver_internal_state])\n\u001B[0m\u001B[1;32m    298\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    299\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0msolution_times_chosen_by_solver\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001B[0m in \u001B[0;36mnew_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    603\u001B[0m                   \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__module__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'in a future version'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    604\u001B[0m                   if date is None else ('after %s' % date), instructions)\n\u001B[0;32m--> 605\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    606\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    607\u001B[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop_v2\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001B[0m\n\u001B[1;32m   2497\u001B[0m       \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2498\u001B[0m       \u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2499\u001B[0;31m       return_same_structure=True)\n\u001B[0m\u001B[1;32m   2500\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2501\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001B[0m\n\u001B[1;32m   2733\u001B[0m                                               list(loop_vars))\n\u001B[1;32m   2734\u001B[0m       \u001B[0;32mwhile\u001B[0m \u001B[0mcond\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2735\u001B[0;31m         \u001B[0mloop_vars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2736\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtry_to_pack\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_basetuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2737\u001B[0m           \u001B[0mpacked\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/math/ode/bdf.py\u001B[0m in \u001B[0;36mmaybe_step\u001B[0;34m(accepted, diagnostics, iterand, solver_internal_state)\u001B[0m\n\u001B[1;32m    373\u001B[0m       \u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbdf_util\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnewton\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbackward_differences\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_num_newton_iters\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    374\u001B[0m                           \u001B[0mnewton_coefficients_array\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mode_fn_vec\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 375\u001B[0;31m                           order, step_size, time, newton_tol, unitary, upper)\n\u001B[0m\u001B[1;32m    376\u001B[0m       \u001B[0mnum_steps\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    377\u001B[0m       \u001B[0mnum_ode_fn_evaluations\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mnewton_num_iters\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/math/ode/bdf_util.py\u001B[0m in \u001B[0;36mnewton\u001B[0;34m(backward_differences, max_num_iters, newton_coefficient, ode_fn_vec, order, step_size, time, tol, unitary, upper)\u001B[0m\n\u001B[1;32m    188\u001B[0m       prev_delta_norm=tf.constant(np.array(-0.), dtype=real_dtype))\n\u001B[1;32m    189\u001B[0m   [iterand] = tf.while_loop(lambda iterand: tf.logical_not(iterand.finished),\n\u001B[0;32m--> 190\u001B[0;31m                             newton_body, [iterand])\n\u001B[0m\u001B[1;32m    191\u001B[0m   return (iterand.converged, iterand.next_backward_difference,\n\u001B[1;32m    192\u001B[0m           iterand.next_state_vec, iterand.num_iters)\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001B[0m in \u001B[0;36mnew_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    603\u001B[0m                   \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__module__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'in a future version'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    604\u001B[0m                   if date is None else ('after %s' % date), instructions)\n\u001B[0;32m--> 605\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    606\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    607\u001B[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop_v2\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001B[0m\n\u001B[1;32m   2497\u001B[0m       \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2498\u001B[0m       \u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2499\u001B[0;31m       return_same_structure=True)\n\u001B[0m\u001B[1;32m   2500\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2501\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001B[0m\n\u001B[1;32m   2733\u001B[0m                                               list(loop_vars))\n\u001B[1;32m   2734\u001B[0m       \u001B[0;32mwhile\u001B[0m \u001B[0mcond\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2735\u001B[0;31m         \u001B[0mloop_vars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2736\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtry_to_pack\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_basetuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2737\u001B[0m           \u001B[0mpacked\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow_probability/python/math/ode/bdf_util.py\u001B[0m in \u001B[0;36mnewton_body\u001B[0;34m(iterand)\u001B[0m\n\u001B[1;32m    140\u001B[0m             \u001B[0mupper\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m             \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0munitary\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrhs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnewaxis\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 142\u001B[0;31m             lower=False))\n\u001B[0m\u001B[1;32m    143\u001B[0m     \u001B[0mnum_iters\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0miterand\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_iters\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 201\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    202\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/linalg_ops.py\u001B[0m in \u001B[0;36mmatrix_triangular_solve\u001B[0;34m(matrix, rhs, lower, adjoint, name)\u001B[0m\n\u001B[1;32m    142\u001B[0m   \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'triangular_solve'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mmatrix\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrhs\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m     return gen_linalg_ops.matrix_triangular_solve(\n\u001B[0;32m--> 144\u001B[0;31m         matrix, rhs, lower=lower, adjoint=adjoint)\n\u001B[0m\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/ops/gen_linalg_ops.py\u001B[0m in \u001B[0;36mmatrix_triangular_solve\u001B[0;34m(matrix, rhs, lower, adjoint, name)\u001B[0m\n\u001B[1;32m   1970\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1971\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1972\u001B[0;31m       \u001B[0m_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1973\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1974\u001B[0m       \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   6860\u001B[0m   \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\" name: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6861\u001B[0m   \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6862\u001B[0;31m   \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6863\u001B[0m   \u001B[0;31m# pylint: enable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6864\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/wishart/lib/python3.7/site-packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Input matrix is not invertible. [Op:MatrixTriangularSolve]"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train():\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "    loss_object = tf.keras.losses.MeanSquaredLogarithmicError()\n",
    "    epochs = 2\n",
    "    t_init, t_final = f64(0.), f64(1)\n",
    "    print('start', 'end', t_init, t_final)\n",
    "    y_init = tf.constant(tf.zeros((num_genes,1), dtype=tf.float64))\n",
    "    sol_times = tf.reshape(t_inducing, -1)\n",
    "    odeint = tfp.math.ode.BDF(atol=1e-5, min_step_size_factor=0.2, max_num_steps=50)\n",
    "    plt.figure()\n",
    "    plt.plot(t_inducing, m_observed[0,0], label='real')\n",
    "\n",
    "    basalrates = list()\n",
    "    decayrates = list()\n",
    "    lengthscales = list()\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch}')\n",
    "        with tf.GradientTape() as tape:\n",
    "            results = odeint.solve(model.call, t_init, y_init,\n",
    "                                               solution_times=sol_times)\n",
    "            # print('states', tf.transpose(results.states))\n",
    "            outputs = tf.transpose(tf.squeeze(results.states))\n",
    "\n",
    "            loss = loss_object(m_observed[0], outputs)\n",
    "            print('loss', loss)\n",
    "            # loss = loss_object(labels, predictions)\n",
    "        # gradients = tape.gradient(results.states, model.basal_rate)\n",
    "        # print('basal', gradients)\n",
    "        trainable_variables = [*model.trainable_variables, *model.kernel.trainable_variables]\n",
    "        gradients = tape.gradient(loss, trainable_variables)\n",
    "        print('gradients', gradients)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "        basalrates.append(model.basal_rate.numpy())\n",
    "        decayrates.append(model.decay_rate.numpy())\n",
    "        lengthscales.append(model.kernel.lengthscales.numpy())\n",
    "        plt.plot(t_inducing, outputs[0], label='epoch'+str(epoch))\n",
    "\n",
    "        # train_loss(loss)\n",
    "        # train_accuracy(labels, predictions)\n",
    "    return outputs, (basalrates, decayrates, lengthscales)\n",
    "\n",
    "outputs, params = train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.kernel.trainable_variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 6))\n",
    "basal, decay, lengthscale = params\n",
    "print(lengthscale)\n",
    "basals = np.array(basal)\n",
    "decays = np.array(decay)\n",
    "lengthscales = np.array(lengthscale)\n",
    "print(lengthscales.shape)\n",
    "plt.subplot(311)\n",
    "plt.plot(basals[:,0])\n",
    "plt.ylim(1, 1.5)\n",
    "plt.subplot(312)\n",
    "plt.plot(decays[:,0])\n",
    "plt.ylim(0.5, 1)\n",
    "plt.subplot(313)\n",
    "plt.plot(lengthscales)\n",
    "plt.ylim(1, 1.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "(5, 7)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_observed[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}