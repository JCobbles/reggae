{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Variational Inference\n",
    "\n",
    "The dataset required is small and is available preprocessed here:\n",
    "\n",
    "- https://drive.google.com/drive/folders/1Tg_3SlKbdv0pDog6k2ys0J79e1-vgRyd?usp=sharing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from lafomo.datasets import P53Data\n",
    "from lafomo.variational.kernels import RBF\n",
    "from lafomo.variational.models import SingleLinearLFM\n",
    "from lafomo.variational.trainer import P53ConstrainedTrainer\n",
    "from lafomo.configuration import VariationalConfiguration\n",
    "from lafomo.utilities.torch import save, load\n",
    "from lafomo.plot import Plotter\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = P53Data(replicate=0, data_dir='../../../data')\n",
    "num_genes = 5\n",
    "num_tfs = 1\n",
    "\n",
    "t_inducing = torch.linspace(0, 12, 10, dtype=torch.float64)\n",
    "t_observed = torch.linspace(0, 12, 7)\n",
    "t_predict = torch.linspace(-1, 13, 80, dtype=torch.float64)\n",
    "\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.plot(dataset[0][1])\n",
    "plt.plot(dataset.m_observed[0, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "options = VariationalConfiguration(\n",
    "    preprocessing_variance=dataset.variance,\n",
    "    learn_inducing=False,\n",
    "    num_samples=50,\n",
    "    kernel_scale=False,\n",
    "    initial_conditions=False\n",
    ")\n",
    "rtol = 1e-1\n",
    "atol = rtol/10\n",
    "\n",
    "model_kwargs = {\n",
    "    'rtol': rtol, 'atol': atol\n",
    "}\n",
    "kernel = RBF(dataset.num_latents, scale=options.kernel_scale, dtype=torch.float64)\n",
    "model = SingleLinearLFM(options, kernel, t_inducing, dataset)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "trainer = P53ConstrainedTrainer(model, optimizer, dataset)\n",
    "plotter = Plotter(model, dataset.gene_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outputs prior to training:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plotter.plot_kinetics()\n",
    "plotter.plot_outputs(t_predict, replicate=0,\n",
    "                     t_scatter=dataset.t_observed, y_scatter=dataset.m_observed,\n",
    "                     model_kwargs=model_kwargs)\n",
    "plotter.plot_latents(t_predict, ylim=(-1, 3), plot_barenco=True, plot_inducing=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tol = 1e-1\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "output = trainer.train(100, rtol=tol, atol=tol/10,\n",
    "                       report_interval=5, plot_interval=5)\n",
    "end = time.time()\n",
    "print(end - start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outputs after training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plotter.plot_losses(trainer, last_x=100)\n",
    "plotter.plot_outputs(t_predict, replicate=0,# ylim=(0, 3),\n",
    "                     t_scatter=dataset.t_observed,\n",
    "                     y_scatter=dataset.m_observed,\n",
    "                     model_kwargs=model_kwargs)\n",
    "plotter.plot_latents(t_predict, ylim=(-2, 3.2), plot_barenco=False, plot_inducing=False)\n",
    "plotter.plot_kinetics()\n",
    "plotter.plot_convergence(trainer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "S = torch.tril(torch.stack(trainer.cholS).squeeze())\n",
    "S = torch.matmul(S, S.transpose(1, 2))\n",
    "plt.imshow(S[-1])\n",
    "plt.colorbar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(model.Kmm[0].detach())\n",
    "plt.colorbar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(model.inducing_inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Ksm = model.kernel(t_predict, model.inducing_inputs)  # (I, T*, Tu)\n",
    "α = torch.cholesky_solve(Ksm.permute([0, 2, 1]), model.L, upper=False).permute([0, 2, 1])  # (I, T*, Tu)\n",
    "m_s = torch.matmul(α, model.q_m)  # (I, T*, 1)\n",
    "m_s = torch.squeeze(m_s, 2)\n",
    "Kss = model.kernel(t_predict)  # (I, T*, T*) this is always scale=1\n",
    "S_Kmm = model.S - model.Kmm  # (I, Tu, Tu)\n",
    "AS_KA = torch.matmul(torch.matmul(α, S_Kmm), torch.transpose(α, 1, 2))  # (I, T*, T*)\n",
    "S_s = (Kss + AS_KA)  # (I, T*, T*)\n",
    "print(S_s.shape)\n",
    "# plt.imshow(S_s.detach()[0])\n",
    "# plt.colorbar()\n",
    "\n",
    "std = torch.sqrt(torch.diagonal(S_s[0])).detach()\n",
    "print(std.shape, std)\n",
    "plt.plot(torch.linspace(0, 1, 80), torch.ones(80))\n",
    "plt.fill_between(torch.linspace(0, 1, 80), torch.ones(80) + std, torch.ones(80) - std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# timepoints = 20\n",
    "# t_temp = torch.linspace(0, 12, timepoints, dtype=torch.float64)\n",
    "# initial_value = torch.zeros((options.num_samples, 5, 1))\n",
    "# samples = model(t_temp, initial_value, return_samples=True, rtol=1e-3, atol=1e-3)\n",
    "# samples = samples.detach().numpy()\n",
    "# fig, ax = plt.subplots(nrows=1) #, figsize=(10, 10))\n",
    "# full_cov = np.zeros((timepoints*5, timepoints*5))\n",
    "# for j in range(5):\n",
    "#     x = samples[:, :, j].squeeze()\n",
    "#     covxx = np.cov(x)\n",
    "#     full_cov[j*timepoints:(j+1)*timepoints, j*timepoints:(j+1)*timepoints] = covxx\n",
    "#\n",
    "#     for k in range(j+1, 5):\n",
    "#         y = samples[:,:, j+1].squeeze()\n",
    "#         covxy = np.cov(x, y)\n",
    "#         full_cov[j*timepoints:(j+1)*timepoints, k*timepoints:(k+1)*timepoints] = covxy[:timepoints, timepoints:]\n",
    "#         full_cov[k*timepoints:(k+1)*timepoints, j*timepoints:(j+1)*timepoints] = covxy[:timepoints, timepoints:]\n",
    "#\n",
    "# ax.imshow(full_cov)\n",
    "# plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mu = samples.mean(axis=1).reshape(-1)\n",
    "# mu = torch.tensor(mu, dtype=torch.float32)\n",
    "# cov = torch.tensor(full_cov, dtype=torch.float32) + torch.eye(5*timepoints) * 1e-1\n",
    "# print(mu.shape, cov.shape)\n",
    "# post_dist = torch.distributions.MultivariateNormal(mu, cov)\n",
    "# fig, ax = plt.subplots(nrows=num_genes, figsize=(5, 10))\n",
    "# for j in range(num_genes):\n",
    "#     ax[j].plot(mu.view(timepoints, num_genes)[:, j])\n",
    "#     for _ in range(10):\n",
    "#         sample = post_dist.sample().view(timepoints, num_genes)\n",
    "#         ax[j].plot(sample[:, j])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save(model, 'variational_linear')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "do_load = False\n",
    "if do_load:\n",
    "    model = load('variational_linear', SingleLinearLFM, num_genes, num_tfs,\n",
    "                 t_inducing, dataset, extra_points=2, fixed_variance=dataset.variance)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    trainer = P53ConstrainedTrainer(model, optimizer, dataset)\n",
    "print(do_load)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-222640c7",
   "language": "python",
   "display_name": "PyCharm (reggae)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}