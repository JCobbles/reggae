{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from lafomo.datasets import P53Data\n",
    "from lafomo.kernels import RBF\n",
    "from lafomo.variational.models import SingleLinearLFM\n",
    "from lafomo.variational.trainer import P53ConstrainedTrainer\n",
    "from lafomo.configuration import VariationalConfiguration\n",
    "from lafomo.utilities.torch import save, load\n",
    "from lafomo.plot import Plotter\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = P53Data(replicate=0)\n",
    "num_genes = 5\n",
    "num_tfs = 1\n",
    "\n",
    "t_inducing = torch.linspace(0, 12, 7, dtype=torch.float64)\n",
    "t_observed = torch.linspace(0, 12, 7)\n",
    "t_predict = torch.linspace(-1, 13, 80, dtype=torch.float64)\n",
    "\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.plot(dataset[0][1])\n",
    "plt.plot(dataset.m_observed[0, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "options = VariationalConfiguration(\n",
    "    num_outputs=num_genes,\n",
    "    num_latents=num_tfs,\n",
    "    preprocessing_variance=dataset.variance,\n",
    "    learn_inducing=False,\n",
    "    num_samples=50,\n",
    "    kernel_scale=False\n",
    ")\n",
    "rtol = 1e-3\n",
    "atol = rtol/10\n",
    "\n",
    "model_kwargs = {\n",
    "    'rtol': rtol, 'atol': atol\n",
    "}\n",
    "kernel = RBF(options.num_latents, scale=options.kernel_scale, dtype=torch.float64)\n",
    "model = SingleLinearLFM(options, kernel, t_inducing, dataset)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "trainer = P53ConstrainedTrainer(model, optimizer, dataset)\n",
    "plotter = Plotter(model, dataset.gene_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outputs prior to training:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plotter.plot_kinetics()\n",
    "plotter.plot_outputs(t_predict, replicate=0,\n",
    "                     t_scatter=dataset.t_observed, y_scatter=dataset.m_observed,\n",
    "                     model_kwargs=model_kwargs)\n",
    "plotter.plot_latents(t_predict, ylim=(-1, 3), plot_barenco=True, plot_inducing=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tol = 5e-3\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "output = trainer.train(1, rtol=tol, atol=tol/10,\n",
    "                       report_interval=5, plot_interval=5)\n",
    "end = time.time()\n",
    "print(end - start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outputs after training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "S = torch.tril(torch.stack(trainer.cholS).squeeze())\n",
    "S = torch.matmul(S, S.transpose(1, 2))\n",
    "plt.imshow(S[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "timepoints = 20\n",
    "t_temp = torch.linspace(0, 12, timepoints, dtype=torch.float64)\n",
    "initial_value = torch.zeros((options.num_samples, 5, 1))\n",
    "samples = model(t_temp, initial_value, return_samples=True, rtol=1e-3, atol=1e-3)\n",
    "samples = samples.detach().numpy()\n",
    "fig, ax = plt.subplots(nrows=1) #, figsize=(10, 10))\n",
    "full_cov = np.zeros((timepoints*5, timepoints*5))\n",
    "for j in range(5):\n",
    "    x = samples[:, :, j].squeeze()\n",
    "    covxx = np.cov(x)\n",
    "    full_cov[j*timepoints:(j+1)*timepoints, j*timepoints:(j+1)*timepoints] = covxx\n",
    "\n",
    "    for k in range(j+1, 5):\n",
    "        y = samples[:,:, j+1].squeeze()\n",
    "        covxy = np.cov(x, y)\n",
    "        full_cov[j*timepoints:(j+1)*timepoints, k*timepoints:(k+1)*timepoints] = covxy[:timepoints, timepoints:]\n",
    "        full_cov[k*timepoints:(k+1)*timepoints, j*timepoints:(j+1)*timepoints] = covxy[:timepoints, timepoints:]\n",
    "\n",
    "ax.imshow(full_cov)\n",
    "plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mu = samples.mean(axis=1).reshape(-1)\n",
    "mu = torch.tensor(mu, dtype=torch.float32)\n",
    "cov = torch.tensor(full_cov, dtype=torch.float32) + torch.eye(5*timepoints) * 1e-1\n",
    "print(mu.shape, cov.shape)\n",
    "post_dist = torch.distributions.MultivariateNormal(mu, cov)\n",
    "fig, ax = plt.subplots(nrows=num_genes, figsize=(5, 10))\n",
    "for j in range(num_genes):\n",
    "    ax[j].plot(mu.view(timepoints, num_genes)[:, j])\n",
    "    for _ in range(10):\n",
    "        sample = post_dist.sample().view(timepoints, num_genes)\n",
    "        ax[j].plot(sample[:, j])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plotter.plot_losses(trainer, last_x=100)\n",
    "plotter.plot_outputs(t_predict, replicate=0, ylim=(0, 3),\n",
    "                     t_scatter=dataset.t_observed,\n",
    "                     y_scatter=dataset.m_observed,\n",
    "                     model_kwargs=model_kwargs)\n",
    "plotter.plot_latents(t_predict, ylim=(-2, 3.2), plot_barenco=True, plot_inducing=False)\n",
    "plotter.plot_kinetics()\n",
    "plotter.plot_convergence(trainer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save(model, 'variational_linear')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "do_load = False\n",
    "if do_load:\n",
    "    model = load('variational_linear', SingleLinearLFM, num_genes, num_tfs,\n",
    "                 t_inducing, dataset, extra_points=2, fixed_variance=dataset.variance)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    trainer = P53ConstrainedTrainer(model, optimizer, dataset)\n",
    "print(do_load)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}